# Image-classification-with-LIME-explainability
Implementation of an image classification Model with the incorporation of Local Interpretable Model-Agnostic Explanations (LIME)


The purpose of this project is to enhance the interpretability and explainability of an image classification model with the aid of Local Interpretable Model-Agnostic
Explanations (LIME) framework. By utilising LIME, The aim is to provide insight into how the model makes predictions on individual images , identify the important regions and or features contributing to the predictions and improve its transparency as well as trust the model in its decision-making process.
